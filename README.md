# Simulation-LRT
A novel analytical procedure that enables the combination of multiple non-exclusive models in a likelihood framework. 

Simulation LRT is an approach where non-nested models may be compared using likelihood ratio tests (Williams, 1970; Lewis, Butler & Gilbert, 2011). The procedure consists of several steps, which are outlined briefly here. First, for two non-nested models, ‘A’ and ‘B’, calculate the likelihood of models ‘A’ and ‘B’ given the parameters of the models and observed data. Next, simulate a large number of datasets under the null model ‘A’, fit each dataset to the null ‘A’ and alternative ‘B’ models, and calculate Likelihood Ratio Test Statistics (LRTS) for each simulated dataset as well as the observed dataset. The proportion of LRTS from the simulated datasets that are more extreme than the observed data is then estimated, and if the observed LRTS is more extreme than 95% of the simulated datasets, the LRT is judged as ‘significant’. Finally, the steps are repeated with the role of ‘null’ and ‘alternative’ model reversed.

The procedure above provides a means of evaluating the fit of data to multiple models that are not statistically nested (as is the case here). As noted by Lewis et al. (2011), this analysis has four potential outcomes. (1) The LRT with A as the null model is non-significant, but the LRT with B as the null is significant. In this case, model A is a better fit than model B. (2) The LRT with B as the null model is non-significant, but the LRT with A as the null is significant. In this case, model B is a better fit than model A. (3) If both LRTs are significant, neither model fits the data well. (4) If neither LRT is significant, the two models cannot be distinguished given the available data. We used this procedure on each pair of the hypotheses described above to determine which hypothesis (if any) provided a better explanation for the observed attack rates.

The LRT procedure described above is quite flexible, in that it allows one to compare the fit of non-nested models to data using likelihood ratio tests. However, the method assumes that all models are mutually exclusive, which is not always the case.

To address this possibility, we developed a likelihood procedure that, given a set of explanatory models, identified the best-fitting model (based on likelihood) where this model consisted of combinations of the previously stated hypotheses. Procedurally, this was accomplished by incorporating weights (w) for each model, which were multiplied by the parameters of each hypothesis.

These weights were then adjusted to maximize the likelihood of a combined hypothesis, with the constraint that the weights sum to 1.0.

Note that for a ‘pure’ model, the weight for that component would be w = 1.0, and the weights for the remaining model contributions would be w = 0.0. We implemented this procedure using the ‘optim’ function in the ‘stats’ package found in ‘R’. We then compared the fit of the combined hypothesis to each ‘pure’ hypothesis using likelihood, AIC, and simulation LRT.
